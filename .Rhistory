d.range <- range(tmp)
s1 <- 1
# ガウシアンカーネルのsdの３倍の余裕を前後に持たせる
d.range. <- c(d.range[1]-3*s1,d.range[2]+3*s1)
# グリッド数
Nval <- 100
d.value <- seq(from=d.range.[1],to=d.range.[2],length=Nval)
# オブジェクトごとに、距離分布を算出する
h.list <- list()
for(i in 1:n.obj){
h.list[[i]] <- matrix(0,length(dANDa[[i]]$a),Nval)
for(j in 1:length(h.list[[i]][,1])){
h.list[[i]][j,] <- my.hist(dANDa[[i]]$d[j,],dANDa[[i]]$a,d.value,s1)
}
}
#matplot(t(h.list[[1]]),type="l")
h.mean <- matrix(0,n.obj,Nval)
for(i in 1:n.obj){
h.mean[i,] <- apply(h.list[[i]] * dANDa[[i]]$a,2,sum)
}
IPmean <- h.mean %*% t(h.mean)
eigenout <- eigen(log(IPmean))
plot(eigenout[[1]])
pairs(eigenout[[2]][,1:4])
ord <- order(eigenout[[2]][,1])
plot(ord)
rg <- range(eigenout[[2]][,1:3])
rgdif <- rg[2]-rg[1]
plot3d(eigenout[[2]][,1:3])
text3d(eigenout[[2]][,1:3],texts=paste("",1:n.obj))
#for(i in 1:n.obj){
#tmpobj <- Objs[[i]]
#tmpobj$X <- tmpobj$X*rgdif/n.obj * 0.8
#tobeadded <- eigenout[[2]][i,1:3] + sign(i %% 2 -0.5)*rnorm(3)*rgdif*0.02
#tmpobj$X <- t(t(tmpobj$X) + tobeadded)
#my.plot.shape(tmpobj,add=TRUE)
#}
ax <- 1:3
plot3d(eigenout[[2]][,ax])
spheres3d(eigenout[[2]][,ax],radius=0.03,color=rep(1:3,each=n.obj0))
text3d(eigenout[[2]][,ax]+0.05,texts=paste("",1:n.obj))
rg <- range(eigenout[[2]][,1:3])
rgdif <- rg[2]-rg[1]
plot3d(eigenout[[2]][,1:3])
#text3d(eigenout[[2]][,1:3],texts=paste("",1:n.obj))
for(i in 1:n.obj){
tmpobj <- Objs[[i]]
tmpobj$X <- tmpobj$X*rgdif/n.obj * 0.8
tobeadded <- eigenout[[2]][i,1:3] + sign(i %% 2 -0.5)*rnorm(3)*rgdif*0.02
tmpobj$X <- t(t(tmpobj$X) + tobeadded)
my.plot.shape(tmpobj,add=TRUE)
}
param <- c(6,2)
Objs <- list()
for(i in 1:n.obj0){
#Objs[[i]] <- my.3Dobj(d=ds[i],k=ks[i],N=15)
A <- A0
A[param[1],param[2]] <- i * 1/n.obj0 * scl
B <- B0
Objs[[cnt]] <- my.3Dobj2(A,B,N=15)
cnt <- cnt+1
}
param <- c(4,3)
for(i in 1:n.obj0){
#Objs[[i]] <- my.3Dobj(d=ds[i],k=ks[i],N=15)
A <- A0
A[param[1],param[2]] <- i * 1/n.obj0 * scl
B <- B0
Objs[[cnt]] <- my.3Dobj2(A,B,N=15)
cnt <- cnt+1
}
for(i in 1:n.obj0){
Objs[[cnt]] <- Objs[[i]]
Objs[[cnt]]$X[,1] <- Objs[[cnt]]$X[,1]*2
cnt <- cnt+1
}
for(i in 1:n.obj0){
Objs[[cnt]] <- list()
Objs[[cnt]] <- Objs[[i]]
Objs[[cnt]]$X[,1] <- Objs[[cnt]]$X[,1]*2
cnt <- cnt+1
}
cnt
n.obj0 <- 10
nn <- 8
A0 <- matrix(0,nn,nn)
A0[1,1] <- 5
B0 <- matrix(0,nn,nn)
cnt <- 1
scl <- 3
param <- c(6,2)
Objs <- list()
for(i in 1:n.obj0){
#Objs[[i]] <- my.3Dobj(d=ds[i],k=ks[i],N=15)
A <- A0
A[param[1],param[2]] <- i * 1/n.obj0 * scl
B <- B0
Objs[[cnt]] <- my.3Dobj2(A,B,N=15)
cnt <- cnt+1
}
param <- c(4,3)
for(i in 1:n.obj0){
#Objs[[i]] <- my.3Dobj(d=ds[i],k=ks[i],N=15)
A <- A0
A[param[1],param[2]] <- i * 1/n.obj0 * scl
B <- B0
Objs[[cnt]] <- my.3Dobj2(A,B,N=15)
cnt <- cnt+1
}
for(i in 1:n.obj0){
#Objs[[cnt]] <- list()
Objs[[cnt]] <- Objs[[i]]
Objs[[cnt]]$X[,1] <- Objs[[cnt]]$X[,1]*2
cnt <- cnt+1
}
n.obj <- length(Objs)
dANDa <- list()
for(i in 1:n.obj){
dANDa[[i]] <- my.pr.v(Objs[[i]]$g,Objs[[i]]$w,Objs[[i]]$tri,Objs[[i]]$X)
}
tmp <- matrix(0,n.obj,2)
for(i in 1:n.obj){
tmp[i,] <- range(dANDa[[i]]$d)
}
d.range <- range(tmp)
s1 <- 1
# ガウシアンカーネルのsdの３倍の余裕を前後に持たせる
d.range. <- c(d.range[1]-3*s1,d.range[2]+3*s1)
# グリッド数
Nval <- 100
d.value <- seq(from=d.range.[1],to=d.range.[2],length=Nval)
# オブジェクトごとに、距離分布を算出する
h.list <- list()
for(i in 1:n.obj){
h.list[[i]] <- matrix(0,length(dANDa[[i]]$a),Nval)
for(j in 1:length(h.list[[i]][,1])){
h.list[[i]][j,] <- my.hist(dANDa[[i]]$d[j,],dANDa[[i]]$a,d.value,s1)
}
}
#matplot(t(h.list[[1]]),type="l")
h.mean <- matrix(0,n.obj,Nval)
for(i in 1:n.obj){
h.mean[i,] <- apply(h.list[[i]] * dANDa[[i]]$a,2,sum)
}
IPmean <- h.mean %*% t(h.mean)
eigenout <- eigen(log(IPmean))
plot(eigenout[[1]])
pairs(eigenout[[2]][,1:4])
ord <- order(eigenout[[2]][,1])
plot(ord)
rg <- range(eigenout[[2]][,1:3])
rgdif <- rg[2]-rg[1]
plot3d(eigenout[[2]][,1:3])
text3d(eigenout[[2]][,1:3],texts=paste("",1:n.obj))
#for(i in 1:n.obj){
#tmpobj <- Objs[[i]]
#tmpobj$X <- tmpobj$X*rgdif/n.obj * 0.8
#tobeadded <- eigenout[[2]][i,1:3] + sign(i %% 2 -0.5)*rnorm(3)*rgdif*0.02
#tmpobj$X <- t(t(tmpobj$X) + tobeadded)
#my.plot.shape(tmpobj,add=TRUE)
#}
rg <- range(eigenout[[2]][,1:3])
rgdif <- rg[2]-rg[1]
plot3d(eigenout[[2]][,1:3])
#text3d(eigenout[[2]][,1:3],texts=paste("",1:n.obj))
for(i in 1:n.obj){
tmpobj <- Objs[[i]]
tmpobj$X <- tmpobj$X*rgdif/n.obj * 0.8
tobeadded <- eigenout[[2]][i,1:3] + sign(i %% 2 -0.5)*rnorm(3)*rgdif*0.02
tmpobj$X <- t(t(tmpobj$X) + tobeadded)
my.plot.shape(tmpobj,add=TRUE)
}
ax <- 1:3
plot3d(eigenout[[2]][,ax])
spheres3d(eigenout[[2]][,ax],radius=0.03,color=rep(1:3,each=n.obj0))
text3d(eigenout[[2]][,ax]+0.05,texts=paste("",1:n.obj))
plot(eigenout[[1]][1:10])
plot(eigenout[[1]][2:10])
n.obj0 <- 10
nn <- 8
A0 <- matrix(0,nn,nn)
A0[1,1] <- 5
B0 <- matrix(0,nn,nn)
cnt <- 1
scl <- 3
param <- c(6,2)
Objs <- list()
for(i in 1:n.obj0){
#Objs[[i]] <- my.3Dobj(d=ds[i],k=ks[i],N=15)
A <- A0
A[param[1],param[2]] <- i * 1/n.obj0 * scl
B <- B0
Objs[[cnt]] <- my.3Dobj2(A,B,N=15)
cnt <- cnt+1
}
param <- c(4,3)
for(i in 1:n.obj0){
#Objs[[i]] <- my.3Dobj(d=ds[i],k=ks[i],N=15)
A <- A0
A[param[1],param[2]] <- i * 1/n.obj0 * scl
B <- B0
Objs[[cnt]] <- my.3Dobj2(A,B,N=15)
cnt <- cnt+1
}
for(i in 1:n.obj0){
#Objs[[cnt]] <- list()
Objs[[cnt]] <- Objs[[i]]
Objs[[cnt]]$X[,1] <- Objs[[cnt]]$X[,1]*2
cnt <- cnt+1
}
for(i in 1:n.obj0){
#Objs[[cnt]] <- list()
Objs[[cnt]] <- Objs[[i+n.obj0]]
Objs[[cnt]]$X[,1] <- Objs[[cnt]]$X[,1]*2
cnt <- cnt+1
}
n.obj <- length(Objs)
dANDa <- list()
for(i in 1:n.obj){
dANDa[[i]] <- my.pr.v(Objs[[i]]$g,Objs[[i]]$w,Objs[[i]]$tri,Objs[[i]]$X)
}
tmp <- matrix(0,n.obj,2)
for(i in 1:n.obj){
tmp[i,] <- range(dANDa[[i]]$d)
}
d.range <- range(tmp)
s1 <- 1
# ガウシアンカーネルのsdの３倍の余裕を前後に持たせる
d.range. <- c(d.range[1]-3*s1,d.range[2]+3*s1)
# グリッド数
Nval <- 100
d.value <- seq(from=d.range.[1],to=d.range.[2],length=Nval)
# オブジェクトごとに、距離分布を算出する
h.list <- list()
for(i in 1:n.obj){
h.list[[i]] <- matrix(0,length(dANDa[[i]]$a),Nval)
for(j in 1:length(h.list[[i]][,1])){
h.list[[i]][j,] <- my.hist(dANDa[[i]]$d[j,],dANDa[[i]]$a,d.value,s1)
}
}
#matplot(t(h.list[[1]]),type="l")
h.mean <- matrix(0,n.obj,Nval)
for(i in 1:n.obj){
h.mean[i,] <- apply(h.list[[i]] * dANDa[[i]]$a,2,sum)
}
IPmean <- h.mean %*% t(h.mean)
eigenout <- eigen(log(IPmean))
plot(eigenout[[1]])
pairs(eigenout[[2]][,1:4])
ord <- order(eigenout[[2]][,1])
plot(ord)
rg <- range(eigenout[[2]][,1:3])
rgdif <- rg[2]-rg[1]
plot3d(eigenout[[2]][,1:3])
text3d(eigenout[[2]][,1:3],texts=paste("",1:n.obj))
#for(i in 1:n.obj){
#tmpobj <- Objs[[i]]
#tmpobj$X <- tmpobj$X*rgdif/n.obj * 0.8
#tobeadded <- eigenout[[2]][i,1:3] + sign(i %% 2 -0.5)*rnorm(3)*rgdif*0.02
#tmpobj$X <- t(t(tmpobj$X) + tobeadded)
#my.plot.shape(tmpobj,add=TRUE)
#}
rg <- range(eigenout[[2]][,1:3])
rgdif <- rg[2]-rg[1]
plot3d(eigenout[[2]][,1:3])
#text3d(eigenout[[2]][,1:3],texts=paste("",1:n.obj))
for(i in 1:n.obj){
tmpobj <- Objs[[i]]
tmpobj$X <- tmpobj$X*rgdif/n.obj * 0.8
tobeadded <- eigenout[[2]][i,1:3] + sign(i %% 2 -0.5)*rnorm(3)*rgdif*0.02
tmpobj$X <- t(t(tmpobj$X) + tobeadded)
my.plot.shape(tmpobj,add=TRUE)
}
ax <- 1:3
plot3d(eigenout[[2]][,ax])
spheres3d(eigenout[[2]][,ax],radius=0.03,color=rep(1:3,each=n.obj0))
text3d(eigenout[[2]][,ax]+0.05,texts=paste("",1:n.obj))
ax <- 1:3
plot3d(eigenout[[2]][,ax])
spheres3d(eigenout[[2]][,ax],radius=0.03,color=rep(1:4,each=n.obj0))
text3d(eigenout[[2]][,ax]+0.05,texts=paste("",1:n.obj))
IIPP <- t(t(-2 * IPmean + diag(IPmean)) + diag(IPmean))
range(IIPP)
image(IIPP)
knitr::opts_chunk$set(echo = TRUE)
#内積行列と確率行列をインプトとして拡大指数型表現分解
library(MASS)
df_simu_theo2 <- function(ip_mat,disP){
#log<P,Q> = 2<sita1,sita2>
sita_ip_est_mat <- log(ip_mat)/2
#固有値分解
eigen_out <- eigen(sita_ip_est_mat)
eigen_value <- eigen_out[[1]]
V <- eigen_out[[2]]
Sigma <- diag(sqrt(abs(eigen_value)))
Sita <- V %*% Sigma
S <- diag(sign(eigen_value))
#range(Sita %*% S %*% t(Sita) - sita_ip_est_mat)
#指数型分布族近似でF_dashを計算
grid_num <- ncol(disP)
sample_num <- nrow(disP)
Psi <- matrix(NA,sample_num,grid_num)
for(i in 1:sample_num){
psi <- sum(sign(eigen_value) * Sita[i,]^2)
Psi[i,] <- rep(psi,grid_num)
}
disP[disP==0] <- .Machine$double.xmin
P_dash <- log(disP) + Psi
Sita_dash_re <- cbind(Sita,rep(1,nrow(Sita)))
F_dash_re <- ginv(Sita_dash_re) %*% P_dash
#結果の出力
result <- list(eigen_value,Sita_dash_re,F_dash_re)
names(result) <- c("eig","Sita_dash_re","F_dash_re")
return(result)
}
#矩形分布
# 始点と台の長さとで矩形分布をパラメタ表現する
# すべての矩形分布間に正の内積が出るよう
# すべての矩形分布は、0に値があるようにする
n <- 100
m <- 300
st <- seq(from=-2,to=-0.1,length=n)
len <- 1-st
spt <- seq(from=min(st)-1,to=max(st + len)+1,length=m)
ht <- 1/len/m
preX <- matrix(0,n,m) #100 sample by 300grid
for(i in 1:n){
tmp <- which(spt>=st[i] & spt<st[i]+len[i])
preX[i,tmp] <- ht[i]
}
X <- diag(1/rowSums(preX)) %*% preX
Q = X %*% t(X)
#X
matplot(t(preX),type="l")
result2 <- df_simu_theo2(Q,X)
eigen_value2 <- result2$eig #固有値
Sita_dash_re2 <- result2$Sita_dash_re #θ座標
F_dash_re2 <- result2$F_dash_re #F and C
F. <- F_dash_re2[-(n+1),]
C. <- F_dash_re2[n+1,]
Theta. <- Sita_dash_re2
Eta. <-F. %*% t(X)
matplot(t(Eta.),type="l")
plot(Eta.[c(1),])
plot(Eta.[1,],Eta.[n,])
boxplot(t(Eta.))
var.Eta. <- apply(Eta.,1,var)
plot(var.Eta.)
plot(var.Eta.,eigen_value2)
Eta.dist <- Theta.dist <- matrix(0,n,n)
for(i in 1:n){
for(j in 1:n){
Eta.dist[i,j] <- sum((Eta.[,i]-Eta.[,j])^2 * sign(eigen_value2))
Theta.dist[i,j] <- sum((Theta.[i,1:n]-Theta.[j,1:n])^2 * sign(eigen_value2))
}
}
image(Eta.dist)
image(Theta.dist)
image(Q)
image(Theta.dist)
length(eigen_value2)
plot(Theta.[,1],Eta.[1,])
dim(Eta.)
boxplot(t(Eta.[((n-3):n),]))
matplot(t(Theta.),type="l")
plot(Theta.[,c(1,n)])
plot(eigen_value2)
plot(F.[1,])
length(eigen_value2)
dim(F.)
matplot(t(diag(eigen_value2)%*%F.),type="l")
plot(F.[n,])
plot(F.[1,],F.[n,])
#KL divを計算
KLdiv_dis <- function(vector1,vector2){
vector1[vector1==0] <- .Machine$double.xmin
vector2[vector2==0] <- .Machine$double.xmin
kldiv <- sum(vector1*(log(vector1/vector2)))
#kldiv <- sum(vector1*log(vector1)-vector1*log(vector2))
return(kldiv)
}
KLdiv_dis2 <- function(theta1,eta1,theta2,eta2){
sum((theta1-theta2)*(eta1-eta2))
}
#Psi(theta)を計算
Psi <- function(theta,eigen_value){
pos_eig_idx <- which(eigen_value >= 0)
neg_eig_idx <- which(eigen_value < 0)
psi <- sum(theta[pos_eig_idx]^2) - sum(theta[neg_eig_idx]^2)
return(psi)
}
#E(Fx)のベクトルを計算
EFx <- function(prob_p,F_dash_re){
n <- nrow(X)
res <- rep(NA,n)
for(i in 1:n){
res[i] <- sum(prob_p*F_dash_re[i,])
}
return(res)
}
#分布間のKL divergence, Nielsenの式の一行目(ExX_kl)のプロット
#Nielsenの式の2行目(psi_kyori)と対称化したKL divergence を描く
kl_kyori <- matrix(NA,n,n)
psi_kyori <- matrix(NA,n,n)
EFx_kl <- matrix(NA,n,n)
kl_div <- matrix(NA,n,n)
for(i in 1:n){
for(j in 1:n){
theta_p <- Sita_dash_re2[i,1:n]
theta_q <- Sita_dash_re2[j,1:n]
prob_p <- X[i,]
prob_q  <- X[j,]
psi_kyori[i,j] <- Psi(theta_p - theta_q,eigen_value2) #左辺
#kl_kyori[i,j] <- 0.5 * (KLdiv_dis(prob_p,prob_q) + KLdiv_dis(prob_q,prob_p))
kl_kyori[i,j] <- 0.5*( KLdiv_dis2(Theta.[i,1:n],Eta.[,i],Theta.[j,1:n],Eta.[,j]) + KLdiv_dis2(Theta.[j,1:n],Eta.[,j],Theta.[i,1:n],Eta.[,i]))
kl_div[i,j] <- KLdiv_dis(prob_p,prob_q)
EFx_kl[i,j] <- Psi(theta_q,eigen_value2) - Psi(theta_p,eigen_value2) - sum((theta_q - theta_p) * EFx(prob_p,F_dash_re2))
}
#cat(i)
}
#拡大指数型分布族表現は2分布間のKL divergence の情報を完全に保持している
range(kl_div-EFx_kl)
plot(kl_div,EFx_kl)
#対称化KL距とPsi(theta_q - theta_p)は強い相関があるが完全には一致しない
#これはNielsenの式の１行めから２行めの変形が、データドリブンに算出されたC,F,psiの組では取ることのできる$\theta$が限定されているために成り立たないからだと考えられる。
plot(psi_kyori[upper.tri(psi_kyori)],kl_kyori[upper.tri(kl_kyori)])
#KL divを計算
KLdiv_dis <- function(vector1,vector2){
vector1[vector1==0] <- .Machine$double.xmin
vector2[vector2==0] <- .Machine$double.xmin
kldiv <- sum(vector1*(log(vector1/vector2)))
#kldiv <- sum(vector1*log(vector1)-vector1*log(vector2))
return(kldiv)
}
KLdiv_dis2 <- function(theta1,eta1,theta2,eta2){
sum((theta1-theta2)*(eta1-eta2))
}
#Psi(theta)を計算
Psi <- function(theta,eigen_value){
pos_eig_idx <- which(eigen_value >= 0)
neg_eig_idx <- which(eigen_value < 0)
psi <- sum(theta[pos_eig_idx]^2) - sum(theta[neg_eig_idx]^2)
return(psi)
}
#E(Fx)のベクトルを計算
EFx <- function(prob_p,F_dash_re){
n <- nrow(X)
res <- rep(NA,n)
for(i in 1:n){
res[i] <- sum(prob_p*F_dash_re[i,])
}
return(res)
}
#分布間のKL divergence, Nielsenの式の一行目(ExX_kl)のプロット
#Nielsenの式の2行目(psi_kyori)と対称化したKL divergence を描く
kl_kyori <- matrix(NA,n,n)
psi_kyori <- matrix(NA,n,n)
EFx_kl <- matrix(NA,n,n)
kl_div <- matrix(NA,n,n)
for(i in 1:n){
for(j in 1:n){
theta_p <- Sita_dash_re2[i,1:n]
theta_q <- Sita_dash_re2[j,1:n]
prob_p <- X[i,]
prob_q  <- X[j,]
psi_kyori[i,j] <- Psi(theta_p - theta_q,eigen_value2) #左辺
#kl_kyori[i,j] <- 0.5 * (KLdiv_dis(prob_p,prob_q) + KLdiv_dis(prob_q,prob_p))
kl_kyori[i,j] <- 0.5*( KLdiv_dis2(Theta.[i,1:n],Eta.[,i],Theta.[j,1:n],Eta.[,j]) + KLdiv_dis2(Theta.[j,1:n],Eta.[,j],Theta.[i,1:n],Eta.[,i]))
kl_div[i,j] <- KLdiv_dis(prob_p,prob_q)
EFx_kl[i,j] <- Psi(theta_q,eigen_value2) - Psi(theta_p,eigen_value2) - sum((theta_q - theta_p) * EFx(prob_p,F_dash_re2))
}
#cat(i)
}
#拡大指数型分布族表現は2分布間のKL divergence の情報を完全に保持している
range(kl_div-EFx_kl)
plot(kl_div,EFx_kl)
#対称化KL距とPsi(theta_q - theta_p)は強い相関があるが完全には一致しない
#これはNielsenの式の１行めから２行めの変形が、データドリブンに算出されたC,F,psiの組では取ることのできる$\theta$が限定されているために成り立たないからだと考えられる。
plot(psi_kyori[upper.tri(psi_kyori)],kl_kyori[upper.tri(kl_kyori)])
plot(psi_kyori,Theta.dist)
#分布間のKL divergence, Nielsenの式の一行目(ExX_kl)のプロット
#Nielsenの式の2行目(psi_kyori)と対称化したKL divergence を描く
kl_kyori <- matrix(NA,n,n)
psi_kyori <- matrix(NA,n,n)
EFx_kl <- matrix(NA,n,n)
kl_div <- matrix(NA,n,n)
for(i in 1:n){
for(j in 1:n){
theta_p <- Sita_dash_re2[i,1:n]
theta_q <- Sita_dash_re2[j,1:n]
prob_p <- X[i,]
prob_q  <- X[j,]
psi_kyori[i,j] <- Psi(theta_p - theta_q,eigen_value2) #左辺
kl_kyori[i,j] <- 0.5 * (KLdiv_dis(prob_p,prob_q) + KLdiv_dis(prob_q,prob_p))
#kl_kyori[i,j] <- 0.5*( KLdiv_dis2(Theta.[i,1:n],Eta.[,i],Theta.[j,1:n],Eta.[,j]) + KLdiv_dis2(Theta.[j,1:n],Eta.[,j],Theta.[i,1:n],Eta.[,i]))
kl_div[i,j] <- KLdiv_dis(prob_p,prob_q)
EFx_kl[i,j] <- Psi(theta_q,eigen_value2) - Psi(theta_p,eigen_value2) - sum((theta_q - theta_p) * EFx(prob_p,F_dash_re2))
}
#cat(i)
}
#対称化KL距とPsi(theta_q - theta_p)は強い相関があるが完全には一致しない
#これはNielsenの式の１行めから２行めの変形が、データドリブンに算出されたC,F,psiの組では取ることのできる$\theta$が限定されているために成り立たないからだと考えられる。
plot(psi_kyori[upper.tri(psi_kyori)],kl_kyori[upper.tri(kl_kyori)])
Eta.dist <- Theta.dist <- ThetaEta.dist <- matrix(0,n,n)
for(i in 1:n){
for(j in 1:n){
Eta.dist[i,j] <- sum((Eta.[,i]-Eta.[,j])^2 * sign(eigen_value2))
Theta.dist[i,j] <- sum((Theta.[i,1:n]-Theta.[j,1:n])^2 * sign(eigen_value2))
ThetaEta.dist[i,j] <- sum((Theta.[i,1:n]-Theta.[j,1:n])*(Eta.[,i]-Eta.[,j]))
}
}
plot(ThetaEta.dist,kl_kyori)
