---
title: "ExponentialFamilyInnerProduct"
author: "ryamada"
date: "2018年1月30日"
output: 
  html_document:
    toc: true
    toc_depth: 6
    number_section: true
---

# 同じ指数型分布の内積

指数型分布が
$$
\log{P(x|\theta)} = C(x) + \sum_{i=1} F_i(x) \theta_i - \psi(\theta)
$$
と表されているとする。

ここで、以下の式変形を素直に行うために、次のように書き換える。

$$
\log{P(x|\theta)} = \sum_{i=0} F_i(x) \theta_i - \psi(\theta)\\
F_0(x) = C(x), \theta_0 =C(onst)
$$

# 分布の内積

$P_1(x|\theta_1)$と$P_2(x|\theta_2)$との内積は以下のように表される。

$$
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \int P_1(x|\theta_1)P_2(x|\theta_2)dx
$$

ちなみに、分布からのランダム標本が得られているときに、ノンパラメトリックな分布推定方法としてカーネル法を採用したとすると、カーネルを用いた分布の異同の大きさを表すカーネル平均 $\frac{1}{NM}\sum_i^N \sum_j^M w_1(x_i) w_2(x_j) K(x_i,x_j)$の極限が上記の内積になっている("カーネル法KLd.Rmd"を参照)。

この分布の内積の式を以下のように変形する。

$$
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \int P_1(x|\theta_1)P_2(x|\theta_2)dx\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \int e^{\sum_{i=0} F_i(x) \theta_{1,i} - \psi(\theta_1)}e^{\sum_{i=0} F_i(x) \theta_{2,i} - \psi(\theta_2)}dx\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \int e^{\sum_{i=0} F_i(x) (\theta_{1,i}+\theta_{2,i})  - (\psi(\theta_1) + \psi(\theta_2))}dx\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{1}{e^{\psi(\theta_1)}e^{\psi(\theta_2)}} \int e^{\sum_{i=0} F_i(x) (\theta_{1,i}+\theta_{2,i})}dx
$$

ここで $\theta_1 + \theta_2 = \theta_{1+2}$とすると、

$$
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{1}{e^{\psi(\theta_1)}e^{\psi(\theta_2)}} \int e^{\sum_{i=0} F_i(x) \theta_{1+2,i}}dx\\
$$
と書き表せる。

今、
$$
\int P(x|\theta_1) dx = \int e^{\sum_{i=0} F_i(x) \theta_{i} - \psi(\theta)} dx = 1\\
\int e^{\sum_{i=0} F_i(x) \theta_{i}} dx  = e^{\psi(\theta)}
$$
であることに注意すると、内積の式はさらに変形できて、

$$
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{1}{e^{\psi(\theta_1)}e^{\psi(\theta_2)}} \int e^{\sum_{i=0} F_i(x) \theta_{1+2,i}}dx\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{1}{e^{\psi(\theta_1)}e^{\psi(\theta_2)}} \int e^{\sum_{i=0} F_i(x) \theta_{1+2,i} - \psi(\theta_{1+2})}e^{\psi(\theta_{1+2})}dx\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{e^{\psi(\theta_{1+2})}}{e^{\psi(\theta_1)}e^{\psi(\theta_2)}} \int e^{\sum_{i=0} F_i(x) \theta_{1+2,i} - \psi(\theta_{1+2})}dx\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{e^{\psi(\theta_{1+2})}}{e^{\psi(\theta_1)}e^{\psi(\theta_2)}}
$$

この式が謂わんとしていることは

+ 指数型分布の内積は、log partition 関数 $\phi(\theta)$と分布パラメタの線形和 $\theta_{1+2} = \theta_1 + \theta_2$とで表現されていることを意味している。

# $IP(P_1(x|\theta_1),P_2(x|\theta_2))$ と$\theta$座標系とをうまく関連付ける

天下り式であるが、以下のように$\psi$を定める。

$$
\psi(\theta) = <\theta,\theta> = \sum_i \theta_i^2
$$

このとき

$$
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{e^{<\theta_{1+2},\theta_{1+2}>}}{e^{<\theta_1,\theta_1>}e^{<\theta_2,\theta_2>}}\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = \frac{e^{<\theta_1,\theta_1>}e^{<\theta_2,\theta_2>}e^{2<\theta_1,\theta_2>}}{e^{<\theta_1,\theta_1>}e^{<\theta_2,\theta_2>}}\\
IP(P_1(x|\theta_1),P_2(x|\theta_2)) = e^{2<\theta_1,\theta_2>}
$$

したがって
$$
LIP(P_1(x|\theta_1),P_2(x|\theta_2))) = \log{IP(P_1(x|\theta_1),P_2(x|\theta_2))} = 2 <\theta_1,\theta_2>
$$


結局、カーネルを使って分布の内積$IP$の推定値が、指数型関数の$\theta$座標の内積と結びついた。

座標の内積が定まれば、その座標系の２点間の二乗ノルムは以下のように書ける。


$$
<\theta_1-\theta_2,\theta_1-\theta_2> = <\theta_1,\theta_1> + <\theta_2,\theta_2> - 2 <\theta_1,\theta_2>
$$

このことは、カーネルを使って分布の内積を推定すると、指数型分布の$\theta$座標系の距離行列が求まることを意味する。

距離行列からはMDSを使うとうまく座標を定めることができるから、$\theta$座標が復元できることがわかる。

そのようにして定めた$\theta$座標に対応する指数型分布の構成要素関数を復元できれば、分布の指数型分布表現が得られるはずである。



# Rでやってみる(MDSの手前まで)

kernlabパッケージには２つの行列標本データを受け取り、mmdを返す関数がある。

@mmdstatsにmmd値が入り、第一要素はbiased mmd値、第二要素はunbiased mmd値(多分)。

```{r}
library(kernlab)
x <- matrix(runif(300),100)
y <- matrix(runif(300)+1,100)


mmdo <- kmmd(x, y)

mmdo
mmdo@mmdstats[1]

```

データをシミュレーション作成してみよう。

$$
P(x|\theta) \sim \theta_1 N(0,1) + \theta_2 N(1,1) + (1-\theta_1-\theta_2) N(4,2)
$$
```{r}
n.dist <- 100
library(MCMCpack)
d <- 3
thetas <- rdirichlet(n.dist,rep(1,d))
means <- c(0,1,4)
sds <- c(1,1,2)
xs <- list()
n.sample <- 1000
i <- 1
xs[[i]] <- c()
tmp <- rmultinom(1,n.sample,thetas[i,])
tmp[1]
tmp[2]
tmp[3]
```

```{r}
n.dist <- 4
library(MCMCpack)
d <- 3
thetas <- rdirichlet(n.dist,rep(1,d))
means <- c(0,1,4)
sds <- c(1,1,2)
xs <- list()
n.sample <- 1000
for(i in 1:n.dist){
  tmp <- rmultinom(1,n.sample,thetas[i,])
  xs[[i]] <- rnorm(tmp[1],means[1],sds[1])
  for(j in 2:d){
    xs[[i]] <- matrix(c(xs[[i]],rnorm(tmp[j],means[j],sds[j])),ncol=1)
  }
}
IP <- matrix(0,n.dist,n.dist)
```

```{r}
my.dist.pair <- function(X1,X2){
	L1 <- apply(X1^2,1,sum)
	L2 <- apply(X2^2,1,sum)
	IP <- X1 %*% t(X2)
	sqrt(outer(L1,L2,"+") - 2 * IP)
}
gamma <- 0.1
for(i in 1:n.dist){
  for(j in i:n.dist){
    tmp <- my.dist.pair(xs[[i]],xs[[j]])
    IP[i,j] <- IP[j,i] <- sum(exp(-gamma*tmp^2))
  }
}
logIP <- log(IP)
D <- matrix(0,n.dist,n.dist)
for(i in 1:n.dist){
  for(j in i:n.dist){
    D[i,j] <- D[j,i] <- 1/2*logIP[i,i]+1/2*logIP[j,j] - logIP[i,j]
  }
}
```

```{r}
D
```
